<!DOCTYPE html>
<html lang="en">

<head>
   <meta charset="utf-8">
   <meta name="viewport" content="width=device-width, initial-scale=1">

   <title>Project | Intonation and Evidence CREU 2016</title>

   <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
   <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
   <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>

   <link href="https://fonts.googleapis.com/css?family=Amaranth:400,400i,700|Titillium+Web:400,400i,700" rel="stylesheet">
   <link rel="stylesheet" href="textscale.css" type="text/css">
   <link rel="stylesheet" href="style.css" type="text/css">

</head>

<body>

   <div class="container">

      <div class="row" name="header" id="header">
         <div class="col-lg-12">
            <h1>Intonation and Evidence</h1>
            <p>Collaborative Research Experience for Undergraduates 2016-2017</p>
            <p>Simmons College, Boston, MA</p>
         </div>
      </div>

      <div class="row" name="nav" id="nav">
         <div class="col-xs-3">
            <span class="nav-button" name="home" id="home"><a href="index.html">home</a></span>
         </div>
         <div class="col-xs-3">
            <span class="nav-button" name="home" id="home"><a href="project.html">project</a></span>
         </div>
         <div class="col-xs-3">
            <span class="nav-button" name="home" id="home"><a href="blog.html">blog</a></span>
         </div>
         <div class="col-xs-3">
            <span class="nav-button" name="home" id="home"><a href="team.html">team</a></span>
         </div>
      </div>

      <div class="row">
         <div class="col-lg-12">
            <div class="section-header">
               <h2>Project Description</h2>
            </div>
         </div>
      </div>

      <div class="row">
         <div class="col-lg-12">
            <div class="section-content">
               <p>Understanding human speech involves interpreting various aspects of spoken language that most humans process unconsciously during a conversation. To comprehend spoken language, a person must grasp not only syntax, pragmatics, and semantics but also the acoustics that convey prosody alongside words.</p>

               <p>Prosodic information is carried by variations in duration, volume, and, primarily, pitch. Because prosody is a separate information channel from the segments that make up words, it is also referred to as supra-segmental. Although there exists disagreement on what might define a prosodic "atom" (analogous to, for example, an element in the alphabet), a practical consensus proposes that accents on words and boundary tones at the end of utterances carry prosodic information. Furthermore, the salient acoustic variation is of high and low tones. The ToBI (Tones and Break Indices) system of pitch accent types, based on Auto-Metrical Theory [12,14], defines a variety of accent types that are High (H*) or Low (L*) or combinations (L+H*, L*+H, etc., where the * indicates alignment with an accented syllable) without imposing any particular meaning to any specific accent type. In addition, it uses a combinations of high and low tones for boundary tones (L-L% for declarative sentences, H-H% for questions).</p>

               <p>In recent years, computers and other automatic systems have been developed with fairly impressive speech recognition capabilities, specifically the ability to recognize a word string, but their speech understanding capabilities remain rudimentary. One reason for this gap is that a full mapping between prosody and meaning has remained elusive. There is no standard dictionary to identify the meanings of prosodic elements. Although investigators (e.g. [1-5,12, 15]) have ascribed meanings to High and Low pitch accents, a reliable mapping algorithm has been difficult to determine conclusively.</p>

               <p>This project explores prosodic variation, focusing specifically on changes in intonation, or pitch, to evaluate the specific pragmatic meanings of various intonation patterns. It further evaluates the effect which a speaker's knowledge in the context a given conversational situation has on the pitch used in producing an utterance. In other words, it investigates whether or not the variation in a speaker's intonation gives clues about the amount of evidence the person has regarding the validity of their statement and whether their listener knows what they know. For example, a speaker uses different prosody when confirming some fact with a listener than they would use when conveying new or contradictory information [8,10]. For instance, imagine two people looking out into a downpour when one says, "It's raining out there," as opposed to the same said informatively to a friend shut up in an interior room in the library. This builds on preliminary findings from current work in Professor Veilleux's laboratory.</p>

               <p>The computational aspect of this project will be to extend these findings to improve automatic systems' speech understanding and synthesis systems by capturing the abstract relationship between prosody and these pragmatic meanings. Automatic speech processing applications can be categorized in three sets: automatic speech recognition (transcribes speech), automatic speech understanding (captures the underlying meaning), and speech synthesis (produces human speech). Currently, prosody in automatic speech recognition and understanding systems discards pitch information entirely. With respect to synthetic speech systems, prosody is implemented in one of two ways: default/neutral or stored exemplars. The exemplar approach works well with very constrained tasks, e.g., "You have one new voicemail," but is unnatural when the synthetic reply is not parallel to the original example. On the other hand, neutral prosody has more flexible applications, as exemplified with Amazon Alexa or unconstrained Siri queries, yet can sound unnatural, especially over an extended dialog.</p>
            </div>
         </div>
      </div>

      <div class="row">
         <div class="col-lg-12">
            <div class="section-header">
               <h2>Background Research</h2>
            </div>
         </div>
      </div>

      <div class="row">
         <div class="col-lg-12">
            <div class="section-content">
               <ol>
                  <li>Arvaniti, Amalia and Gina Garding. 2007. “Dialectal variation in the rising accents of American English.” J. Cole &amp; J. H. Hualde &amp; (eds), Papers in Laboratory Phonology 9: Change in Phonology. Mouton de Gruyter.</li>
                  <li>Barnes, Jonathan, Alejna Brugos, Stefanie Shattuck-Hufnagel, and Nanette Veilleux. 2011. “On the nature of perceptual differences between accentual peaks and plateaux.” In Oliver Niebuhr &amp; Hartmut Pfitzinger (eds.), Prosodies: Context, Function, Communication. Berlin/New York: Mouton de Gruyter.</li>
                  <li>Barnes, Jonathan, Nanette Veilleux, Alejna Brugos, and Stefanie Shattuck-Hufnagel. 2012. “Tonal Center of Gravity: A global approach to tonal implementation in a level-based intonational phonology.” Laboratory Phonology.</li>
                  <li>Barnes, Jonathan, Nanette Veilleux, Alejna Brugos, &amp; Stefanie Shattuck-Hufnagel. “Turning points, tonal targets, and the English L- phrase accent.” Language and Cognitive Processes Volume 25, Issue 7-9, 2010. Special Issue: Experimental and Theoretical Advances in Prosody.</li>
                  <li>Bartels, C., 2014. The intonation of English statements and questions: A compositional interpretation.</li>
                  <li>Boersma, Paul and David Weenink. 2009. “Praat: doing phonetics by computer.” (Version 5.1). <a href="http://www.praat.org">http://www.praat.org</a></li>
                  <li>Festival Speech Synthesis Systems <a href="http://www.cstr.ed.ac.uk/projects/festival/">http://www.cstr.ed.ac.uk/projects/festival/</a>" accessed May 14, 2016.</li>
                  <li>Gunlogson, C., 2008. A Question of Commitment. Belgian Journal of Linguistics, 22, 101–136.</li>
                  <li>Hirschberg, Julia, Diane Litman, Janet Pierrehumbert, and G. Ward. 1987. “Intonation and the Intentional Structure of Discourse.” Proceedings of IJCAI-87, Milan, August.</li>
                  <li>Northrup, O., 2014. Grounds for Commitment. Ph.D. thesis, UC Santa Cruz.</li>
                  <li>Pierrehumbert, J.B., The Phonetics and Phonology of English Intonation, PhD thesis, MIT, 1980.</li>
                  <li>Pierrehumbert, J. &amp; J. Hirschberg, 1990. The Meaning of Intonational Contours in the Interpretation of Discourse. In Intentions in Communication.</li>
                  <li>Speech Kitchen, Automatic Speech Recognition <a href="http://speechkitchen.org/">http://speechkitchen.org/</a>" accessed May 14, 2016.</li>
                  <li>Veilleux, N., Brugos, A. and Shattuck-Hufnagel, S.Transcribing Prosodic Structure of Spoken Utterances with ToBI, OpenCourseWare, Massachusetts Institute of Technology, accessed May 14, 2016. <a href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-911-transcribing-prosodic-structure-of-spoken-utterances-with-tobi-january-iap-2006/">http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-911-transcribing-prosodic-structure-of-spoken-utterances-with-tobi-january-iap-2006/</a></li>
                  <li>Watson, D., M. Tanenhaus &amp; C. Gunlogson, 2008. Interpreting Pitch Accents in Online Comprehension: H*vs. L+H*. Cognitive Science, 32, 1232–1244.</li>
               </ol>
            </div>
         </div>
      </div>

   </div>

</body>

</html>
